{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xoxTkoVlvYKv"
      },
      "source": [
        "# Part I. One-sided finite differences"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZzBJ3S_vYK-"
      },
      "source": [
        "Write a function, `deriv`, which computes a derivative of its argument at a given point, $x$, using a one-sided finite difference rule with a given step side $h$, with the approximation order of $O(h^2)$. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "id": "PCyCTxJDvYLA"
      },
      "outputs": [],
      "source": [
        "def deriv(f, x, h):\n",
        "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
        "    \n",
        "    Compute the derivative using the one-sided rule of the approximation order of $O(h)$.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    f : callable\n",
        "        The function to differentiate\n",
        "    x : float\n",
        "        The point to compute the derivative at.\n",
        "    h : float\n",
        "        The step size for the finite different rule.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    fder : derivative of f(x) at point x using the step size h.\n",
        "    \"\"\"\n",
        "    x1 = x + h\n",
        "    dx = x1 - x  #to prevent floating point error\n",
        "    df = f(x1) - f(x)\n",
        "    return df / dx\n",
        "\n",
        "\n",
        "def deriv2(f, x, h):\n",
        "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
        "  \n",
        "    Compute the derivative using the two-point one-sided rule of the approximation order of $O(h^2)$.\n",
        "  \n",
        "    Parameters\n",
        "    ----------\n",
        "    f : callable\n",
        "        The function to differentiate\n",
        "    x : float\n",
        "        The point to compute the derivative at.\n",
        "    h : float\n",
        "        The step size for the finite different rule.\n",
        "      \n",
        "    Returns\n",
        "    -------\n",
        "    fder : derivative of f(x) at point x using the step size h.\n",
        "    \"\"\"\n",
        "    x1 = x + h\n",
        "    x2 = x + 2*h\n",
        "    dx = x2 - x\n",
        "    df = -f(x2) + 4*f(x1) - 3*f(x)\n",
        "    return df / dx\n",
        "\n",
        "def deriv3(f, x, h):\n",
        "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
        "    \n",
        "    Compute the derivative using the three-point one-sided rule of the approximation order of $O(h^2)$.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    f : callable\n",
        "        The function to differentiate\n",
        "    x : float\n",
        "        The point to compute the derivative at.\n",
        "    h : float\n",
        "        The step size for the finite different rule.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    fder : derivative of f(x) at point x using the step size h.\n",
        "    \"\"\"\n",
        "    x1 = x + h\n",
        "    x2 = x + 2*h\n",
        "    x3 = x + 3*h\n",
        "    dx = x3 - x2\n",
        "    df = 1 / 3 * f(x3) - 3 / 2 * f(x2) + 3 * f(x1) - 11 / 6 * f(x) \n",
        "    return df / dx\n",
        "\n",
        "def deriv3_ai(f, x, h):\n",
        "    \"\"\" Compute a derivative of `f` at point `x` with step size `h`.\n",
        "    \n",
        "    Compute the derivative using the three-point one-sided rule of the approximation order of $O(h^2)$.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    f : callable\n",
        "        The function to differentiate\n",
        "    x : float\n",
        "        The point to compute the derivative at.\n",
        "    h : float\n",
        "        The step size for the finite different rule.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    fder : derivative of f(x) at point x using the step size h.\n",
        "    \"\"\"\n",
        "    x1 = x + h\n",
        "    x2 = x + 2*h\n",
        "    x3 = x + 3*h\n",
        "    dx = x3 - x\n",
        "    df = -f(x3) + 3*f(x2) - 3*f(x1) + f(x) \n",
        "    return df / dx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DddJ8s4CvYLE"
      },
      "source": [
        "#### Test I.1\n",
        "\n",
        "Test your function on a simple test case: differentiate $f(x) = x^3$ at $x=0$. Comment on whether your results are consistent with the expected value of $f'(x) = 0$ and on an expected scaling with $h\\to 0$.\n",
        "\n",
        " (10% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lgeNSYTFvYLF",
        "outputId": "c38e0061-49a5-4697-af73-5f2dcb05991c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.010000 --  0.0001\n",
            "0.001000 --   1e-06\n",
            "0.000100 --   1e-08\n",
            "0.000010 --   1e-10\n",
            "0.000001 --   1e-12\n"
          ]
        }
      ],
      "source": [
        "x = 0\n",
        "for h in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6]:\n",
        "    err = deriv(lambda x: x ** 3, x, h)\n",
        "    print(\"%5f -- %7.4g\" % (h, err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eDkVUvPvYLG"
      },
      "source": [
        "The results are consistent with the expected value of $f'(x)=0$. The error is $O(N^2)$ with $h\\to 0$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XjIIn-RvYLH"
      },
      "source": [
        "### Test I.2\n",
        "\n",
        "Now use a slightly more complicated function, $f(x) = x^2 \\log{x}$, evaluate the derivative at $x=1$ using your one-sided rule and a two-point one-sided rule. Roughly estimate the value of $h$ where the error stops decreasing, for these two schemes. \n",
        "(15% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "collapsed": true,
        "id": "WhH77gOcvYLI"
      },
      "outputs": [],
      "source": [
        "from math import log\n",
        "\n",
        "def f(x):\n",
        "    return x**2 * log(x)\n",
        "    \n",
        "def fder(x):\n",
        "    return x * (2.*log(x) + 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "2Dq1Q8w5vYLK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71c6ef8a-4774-43f2-c617-b33b201f3efb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-point:\n",
            "0.010000000000000 -- 0.01503\n",
            "0.001000000000000 --  0.0015\n",
            "0.000100000000000 -- 0.00015\n",
            "0.000010000000000 -- 1.5e-05\n",
            "0.000001000000000 -- 1.5e-06\n",
            "0.000000100000000 -- 1.5e-07\n",
            "0.000000010000000 -- 1.5e-08\n",
            "0.000000001000000 -- 1.5e-09\n",
            "0.000000000100000 -- 1.5e-10\n",
            "0.000000000010000 -- 1.5e-11\n",
            "0.000000000001000 -- 1.5e-12\n",
            "0.000000000000100 -- 1.499e-13\n",
            "0.000000000000010 -- 1.51e-14\n",
            "0.000000000000001 -- 1.554e-15\n",
            "Two-point:\n",
            "0.010000000000000 -- -6.617e-05\n",
            "0.001000000000000 -- -6.662e-07\n",
            "0.000100000000000 -- -6.666e-09\n",
            "0.000010000000000 -- -4.446e-11\n",
            "0.000001000000000 -- -2.227e-10\n",
            "0.000000100000000 -- 2.22e-09\n",
            "0.000000010000000 -- -2.22e-08\n",
            "0.000000001000000 -- 2.22e-07\n",
            "0.000000000100000 --       0\n",
            "0.000000000010000 -- -1.11e-16\n",
            "0.000000000001000 -- 0.000222\n",
            "0.000000000000100 -- -0.00222\n",
            "0.000000000000010 --       0\n",
            "0.000000000000001 --  0.2222\n"
          ]
        }
      ],
      "source": [
        "x = 1\n",
        "\n",
        "print(\"One-point:\")\n",
        "for h in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]:\n",
        "    err = deriv(f, x, h) - fder(x)\n",
        "    print(\"%16.15f -- %7.4g\" % (h, err))\n",
        "\n",
        "print(\"Two-point:\")\n",
        "for h in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]:\n",
        "    err = deriv2(f, x, h) - fder(x)\n",
        "    print(\"%16.15f -- %7.4g\" % (h, err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-LPipE7nvYLL"
      },
      "source": [
        "### Test I.3 \n",
        "\n",
        "Now try differentiating $x^2 \\log(x)$ at $x=0$. Use the three-point one-sided rule. Note that to evaluate the function at zero, you need to special-case this value. Check the scaling of the error with $h$, explain your results. \n",
        "(25% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "OM15LeA_vYLL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a886d838-a058-4ab0-bf70-14a3432ddd1d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-point:\n",
            "0.010000000000000 -- -0.04605\n",
            "0.001000000000000 -- -0.006908\n",
            "0.000100000000000 -- -0.000921\n",
            "0.000010000000000 -- -0.0001151\n",
            "0.000001000000000 -- -1.382e-05\n",
            "0.000000100000000 -- -1.612e-06\n",
            "0.000000010000000 -- -1.842e-07\n",
            "0.000000001000000 -- -2.072e-08\n",
            "0.000000000100000 -- -2.303e-09\n",
            "0.000000000010000 -- -2.533e-10\n",
            "0.000000000001000 -- -2.763e-11\n",
            "0.000000000000100 -- -2.993e-12\n",
            "0.000000000000010 -- -3.224e-13\n",
            "0.000000000000001 -- -3.454e-14\n",
            "Two-point:\n",
            "0.010000000000000 -- -0.01386\n",
            "0.001000000000000 -- -0.001386\n",
            "0.000100000000000 -- -0.0001386\n",
            "0.000010000000000 -- -1.386e-05\n",
            "0.000001000000000 -- -1.386e-06\n",
            "0.000000100000000 -- -1.386e-07\n",
            "0.000000010000000 -- -1.386e-08\n",
            "0.000000001000000 -- -1.386e-09\n",
            "0.000000000100000 -- -1.386e-10\n",
            "0.000000000010000 -- -1.386e-11\n",
            "0.000000000001000 -- -1.386e-12\n",
            "0.000000000000100 -- -1.386e-13\n",
            "0.000000000000010 -- -1.386e-14\n",
            "0.000000000000001 -- -1.386e-15\n",
            "Three-point:\n",
            "0.010000000000000 -- -0.00863\n",
            "0.001000000000000 -- -0.000863\n",
            "0.000100000000000 -- -8.63e-05\n",
            "0.000010000000000 -- -8.63e-06\n",
            "0.000001000000000 -- -8.63e-07\n",
            "0.000000100000000 -- -8.63e-08\n",
            "0.000000010000000 -- -8.63e-09\n",
            "0.000000001000000 -- -8.63e-10\n",
            "0.000000000100000 -- -8.63e-11\n",
            "0.000000000010000 -- -8.63e-12\n",
            "0.000000000001000 -- -8.63e-13\n",
            "0.000000000000100 -- -8.63e-14\n",
            "0.000000000000010 -- -8.63e-15\n",
            "0.000000000000001 -- -8.63e-16\n",
            "Three-point(AI generated):\n",
            "0.010000000000000 -- -0.005232\n",
            "0.001000000000000 -- -0.0005232\n",
            "0.000100000000000 -- -5.232e-05\n",
            "0.000010000000000 -- -5.232e-06\n",
            "0.000001000000000 -- -5.232e-07\n",
            "0.000000100000000 -- -5.232e-08\n",
            "0.000000010000000 -- -5.232e-09\n",
            "0.000000001000000 -- -5.232e-10\n",
            "0.000000000100000 -- -5.232e-11\n",
            "0.000000000010000 -- -5.232e-12\n",
            "0.000000000001000 -- -5.232e-13\n",
            "0.000000000000100 -- -5.232e-14\n",
            "0.000000000000010 -- -5.232e-15\n",
            "0.000000000000001 -- -5.232e-16\n"
          ]
        }
      ],
      "source": [
        "def f(x):\n",
        "    if x == 0:\n",
        "        # the limit of $x^2 log(x)$ at $x-> 0$ is zero, even though log(x) is undefined at x=0\n",
        "        return 0.0\n",
        "    else:\n",
        "        return x**2 * log(x)\n",
        "    \n",
        "def fder(x):\n",
        "    if x == 0:\n",
        "        return 0.0\n",
        "    else:\n",
        "        return x*(2*log(x) + 1)\n",
        "\n",
        "x = 0\n",
        "\n",
        "print(\"One-point:\")\n",
        "for h in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]:\n",
        "    err = deriv(f, x, h) - fder(x)\n",
        "    print(\"%16.15f -- %7.4g\" % (h, err))\n",
        "\n",
        "print(\"Two-point:\")\n",
        "for h in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]:\n",
        "    err = deriv2(f, x, h) - fder(x)\n",
        "    print(\"%16.15f -- %7.4g\" % (h, err))\n",
        "\n",
        "print(\"Three-point:\")\n",
        "for h in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]:\n",
        "    err = deriv3(f, x, h) - fder(x)\n",
        "    print(\"%16.15f -- %7.4g\" % (h, err))\n",
        "\n",
        "print(\"Three-point(AI generated):\")\n",
        "for h in [1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10, 1e-11, 1e-12, 1e-13, 1e-14, 1e-15]:\n",
        "    err = deriv3_ai(f, x, h) - fder(x)\n",
        "    print(\"%16.15f -- %7.4g\" % (h, err))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eHSSg36vYLN"
      },
      "source": [
        "The scaling is $O(N)$ regardless of chosen function.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKfwyIg8vYLO"
      },
      "source": [
        "# Part II. Midpoint rule "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEYIp4CtvYLQ"
      },
      "source": [
        "Write a function which computes a definite integral using the midpoint rule up to a given error, $\\epsilon$. Estimate the error by comparing the estimates of the integral at $N$ and $2N$ elementary intervals. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "id": "IUSdiVMWvYLQ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def midpoint_rule(func, a, b, eps):\n",
        "    \"\"\" Calculate the integral of f from a to b using the midpoint rule.\n",
        "    \n",
        "    Parameters\n",
        "    ----------\n",
        "    func : callable\n",
        "        The function to integrate.\n",
        "    a : float\n",
        "        The lower limit of integration.\n",
        "    b : float\n",
        "        The upper limit of integration.\n",
        "    eps : float\n",
        "        The target accuracy of the estimate.\n",
        "        \n",
        "    Returns\n",
        "    -------\n",
        "    integral : float\n",
        "        The estimate of $\\int_a^b f(x) dx$.\n",
        "    \"\"\"\n",
        "    N = 1\n",
        "    while True:\n",
        "        h = (b - a) / N\n",
        "        x = np.linspace(a + h/2, b - h/2, N)\n",
        "        integral = h * np.sum(func(x))\n",
        "        N *= 2\n",
        "        h = (b - a) / N\n",
        "        x = np.linspace(a + h/2, b - h/2, N)\n",
        "        integral2 = h * np.sum(func(x))\n",
        "        if np.abs(integral - integral2) < eps:\n",
        "            return (integral2, N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-njmjXpvYLS"
      },
      "source": [
        "### Test II.1\n",
        "\n",
        "Test your midpoint rule on a simple integral, which you can calculate by paper and pencil.\n",
        "\n",
        "Compare the rate of convergence to the expected $O(N^{-2})$ scaling by studying the number of intervals required for a given accuracy $\\epsilon$.\n",
        "\n",
        "Compare the numerical results to the value you calculated by hand. Does the deviation agree with your estimate of the numerical error?\n",
        "(20% of the total grade)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for eps in [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9]:\n",
        "  integral, n = midpoint_rule(lambda x: x ** 2, 0, 1, eps)\n",
        "  dev = abs(integral - 1/3)\n",
        "  print(\"%7.4g -- %16.14f -- %5d -- %7.4g\" % (eps, integral, n, dev))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmV9EJWuYdHI",
        "outputId": "c9dc6570-f30d-4034-9cd7-630105858e8e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "    0.1 -- 0.31250000000000 --     2 -- 0.02083\n",
            "   0.01 -- 0.33203125000000 --     8 -- 0.001302\n",
            "  0.001 -- 0.33300781250000 --    16 -- 0.0003255\n",
            " 0.0001 -- 0.33331298828125 --    64 -- 2.035e-05\n",
            "  1e-05 -- 0.33333206176758 --   256 -- 1.272e-06\n",
            "  1e-06 -- 0.33333301544189 --   512 -- 3.179e-07\n",
            "  1e-07 -- 0.33333331346512 --  2048 -- 1.987e-08\n",
            "  1e-08 -- 0.33333333209157 --  8192 -- 1.242e-09\n",
            "  1e-09 -- 0.33333333302289 -- 16384 -- 3.104e-10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "frjmRlyevYLT"
      },
      "source": [
        "### Test II.2\n",
        "\n",
        "Now use your midpoint rule to compute the value of\n",
        "\n",
        "$$\n",
        "\\int_0^1\\! \\frac{\\sin{\\sqrt{x}}}{x}\\, dx\n",
        "$$\n",
        "\n",
        "up to a predefined accuracy of $\\epsilon=10^{-4}$.\n",
        "\n",
        "Note that the integral contains an integrable singularity at the lower limit. Do calculations two ways: first, do a straightforward computation; next, subtract the singularity. Compare the number of iterations required to achieve the accuracy of $\\epsilon$.\n",
        "\n",
        "(30% of the total grade)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "collapsed": true,
        "id": "7rdwYekfvYLT"
      },
      "outputs": [],
      "source": [
        "def f(x: np.ndarray) -> np.ndarray:\n",
        "    return np.sin(np.sqrt(x)) / x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "collapsed": true,
        "id": "udreq7KNvYLU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05c52688-554f-490c-b83f-1f5422fdb719"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 0.0001 -- 1.89195728920431 -- 8388608 -- 0.0002127\n",
            " 0.0001 -- 1.87214704336622 -- 32768 -- 0.02002\n"
          ]
        }
      ],
      "source": [
        "integral, n = midpoint_rule(f, 0, 1, 1e-4)\n",
        "dev = abs(integral - 1.89217)\n",
        "print(\"%7.4g -- %16.14f -- %5d -- %7.4g\" % (1e-4, integral, n, dev))\n",
        "\n",
        "integral, n = midpoint_rule(f, 0.0001, 1, 1e-4)\n",
        "dev = abs(integral - 1.89217)\n",
        "print(\"%7.4g -- %16.14f -- %5d -- %7.4g\" % (1e-4, integral, n, dev))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Straight forward computation gives us more accurate results (comparing to WolframAlpha), but in takes way more iterations to compute"
      ],
      "metadata": {
        "id": "TL5BE4Mid6XN"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}